{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14ac9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! git clone https://github.com/google-research/maxim/\n",
    "# %cd ./maxim\n",
    "\n",
    "# !pip install -r requirements.txt\n",
    "# !pip install --upgrade jax\n",
    "# !pip install gdown\n",
    "# !pip uninstall jax\n",
    "\n",
    "# !python setup.py build\n",
    "# !python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49cd2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys   \n",
    "# !{sys.executable} -m pip install pillow matplotlib cog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bdcc2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/j-k8e104/maxim\n"
     ]
    }
   ],
   "source": [
    "cd maxim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "752afcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import importlib\n",
    "import io\n",
    "import os\n",
    "import math\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import gdown # to download weights from Drive\n",
    "\n",
    "import flax\n",
    "import jax.numpy as jnp\n",
    "import ml_collections\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from jax.experimental import jax2tf\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n",
    "\n",
    "# below code lines are from run_eval.py\n",
    "_MODEL_FILENAME = 'maxim'\n",
    "\n",
    "_MODEL_VARIANT_DICT = {\n",
    "    'Denoising': 'S-3',\n",
    "    'Deblurring': 'S-3',\n",
    "    'Deraining': 'S-2',\n",
    "    'Dehazing': 'S-2',\n",
    "    'Enhancement': 'S-2',\n",
    "}\n",
    "\n",
    "_MODEL_CONFIGS = {\n",
    "    'variant': '',\n",
    "    'dropout_rate': 0.0,\n",
    "    'num_outputs': 3,\n",
    "    'use_bias': True,\n",
    "    'num_supervision_scales': 3,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9eb862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sizeof_fmt(size, suffix='B'):\n",
    "    \"\"\"Get human readable file size.\n",
    "    Args:\n",
    "        size (int): File size.\n",
    "        suffix (str): Suffix. Default: 'B'.\n",
    "    Return:\n",
    "        str: Formated file siz.\n",
    "    \"\"\"\n",
    "    for unit in ['', 'K', 'M', 'G', 'T', 'P', 'E', 'Z']:\n",
    "        if abs(size) < 1024.0:\n",
    "            return f'{size:3.1f} {unit}{suffix}'\n",
    "        size /= 1024.0\n",
    "    return f'{size:3.1f} Y{suffix}'\n",
    "\n",
    "\n",
    "def download_file_from_google_drive(file_id, save_path):\n",
    "    \"\"\"Download files from google drive.\n",
    "\n",
    "    Ref:\n",
    "    https://stackoverflow.com/questions/25010369/wget-curl-large-file-from-google-drive  # noqa E501\n",
    "\n",
    "    Args:\n",
    "        file_id (str): File id.\n",
    "        save_path (str): Save path.\n",
    "    \"\"\"\n",
    "\n",
    "    session = requests.Session()\n",
    "    URL = 'https://docs.google.com/uc?export=download'\n",
    "    params = {'id': file_id}\n",
    "\n",
    "    response = session.get(URL, params=params, stream=True)\n",
    "    token = get_confirm_token(response)\n",
    "    if token:\n",
    "        params['confirm'] = token\n",
    "        response = session.get(URL, params=params, stream=True)\n",
    "\n",
    "    # get file size\n",
    "    response_file_size = session.get(\n",
    "        URL, params=params, stream=True, headers={'Range': 'bytes=0-2'})\n",
    "    if 'Content-Range' in response_file_size.headers:\n",
    "        file_size = int(\n",
    "            response_file_size.headers['Content-Range'].split('/')[1])\n",
    "    else:\n",
    "        file_size = None\n",
    "\n",
    "    save_response_content(response, save_path, file_size)\n",
    "\n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "    return None\n",
    "\n",
    "\n",
    "def save_response_content(response,\n",
    "                          destination,\n",
    "                          file_size=None,\n",
    "                          chunk_size=32768):\n",
    "    if file_size is not None:\n",
    "        pbar = tqdm(total=math.ceil(file_size / chunk_size), unit='chunk')\n",
    "\n",
    "        readable_file_size = sizeof_fmt(file_size)\n",
    "    else:\n",
    "        pbar = None\n",
    "\n",
    "    with open(destination, 'wb') as f:\n",
    "        downloaded_size = 0\n",
    "        for chunk in response.iter_content(chunk_size):\n",
    "            downloaded_size += chunk_size\n",
    "            if pbar is not None:\n",
    "                pbar.update(1)\n",
    "                pbar.set_description(f'Download {sizeof_fmt(downloaded_size)} '\n",
    "                                     f'/ {readable_file_size}')\n",
    "            if chunk:  # filter out keep-alive new chunks\n",
    "                f.write(chunk)\n",
    "        if pbar is not None:\n",
    "            pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebde3407",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resize(path, new_width_height = 1280, save_image = False, convert_RGB = True, clip_full_hd = False, quality = 100):\n",
    "  '''\n",
    "  Resize and return Given Image\n",
    "  args:\n",
    "    path: Image Path\n",
    "    new_width_height = Reshaped image's width and height. # If integer is given, it'll keep the aspect ratio as it is by shrinking the Bigger dimension (width or height) to the max of new_width_height  and then shring the smaller dimension accordingly \n",
    "    save_image = Whether to save the image or not\n",
    "    convert_RGB: Whether to Convert the RGBA image to RGB (by default backgroud is white)\n",
    "  '''\n",
    "  image = Image.open(path)\n",
    "  w, h = image.size\n",
    "\n",
    "  fixed_size = new_width_height if isinstance(new_width_height, int) else False\n",
    "\n",
    "  if fixed_size:\n",
    "    if h > w:\n",
    "      fixed_height = fixed_size\n",
    "      height_percent = (fixed_height / float(h))\n",
    "      width_size = int((float(w) * float(height_percent)))\n",
    "      image = image.resize((width_size, fixed_height), Image.NEAREST)\n",
    "\n",
    "    else:\n",
    "      fixed_width = fixed_size\n",
    "      width_percent = (fixed_width / float(w))\n",
    "      height_size = int((float(h) * float(width_percent)))\n",
    "      image = image.resize((fixed_width, height_size), Image.NEAREST) # Try Image.ANTIALIAS inplace of Image.NEAREST\n",
    "\n",
    "  else:\n",
    "    image = image.resize(new_width_height)\n",
    "\n",
    "  if image.mode == \"RGBA\" and convert_RGB:\n",
    "    # image.load() # required for png.split()\n",
    "    # new = Image.new(\"RGB\", image.size, (255, 255, 255)) # White Background\n",
    "    # image = new.paste(image, mask=image.split()[3]) # 3 is the alpha channel\n",
    "\n",
    "    new = Image.new(\"RGBA\", image.size, \"WHITE\") # Create a white rgba background\n",
    "    new.paste(image, (0, 0), image) # Paste the image on the background.\n",
    "    image = new.convert('RGB')\n",
    "\n",
    "  if save_image:\n",
    "    image.save(path, quality = quality)\n",
    "\n",
    "  return image\n",
    "\n",
    "\n",
    "class DummyFlags():\n",
    "  def __init__(self, ckpt_path:str, task:str, input_dir: str = \"./maxim/images/Enhancement\", output_dir:str = \"./maxim/images/Results\", has_target:bool = False, save_images:bool = True, geometric_ensemble:bool = False):\n",
    "    '''\n",
    "    Builds the dummy flags which replicates the behaviour of Terminal CLI execution (same as ArgParse)\n",
    "    args:\n",
    "      ckpt_path: Saved Model CheckPoint: Find all the checkpoints for pre trained models at https://console.cloud.google.com/storage/browser/gresearch/maxim/ckpt/\n",
    "      task: Task for which the model waas trained. Each task uses different Data and Checkpoints. Find the details of tasks and respective checkpoints details at: https://github.com/google-research/maxim#results-and-pre-trained-models\n",
    "      input_dir: Input Directory. We do not need it here as we are directly passing one image at a time\n",
    "      output_dir: Also not needed in out code\n",
    "      has_target: Used to calculate PSNR and SSIM calculation. Not needed in our case\n",
    "      save_images: Used in CLI command where images were saved in loop. Not needed in our case\n",
    "      geometric_ensemble: Was used in training part and as it is just an Inference part, it is not needed\n",
    "\n",
    "    '''\n",
    "    self.ckpt_path = ckpt_path\n",
    "    self.task = task\n",
    "    self.input_dir = input_dir\n",
    "    self.output_dir = output_dir\n",
    "    self.has_target = has_target\n",
    "    self.save_images = save_images\n",
    "    self.geometric_ensemble = geometric_ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd019d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\n",
    "def recover_tree(keys, values):\n",
    "  \"\"\"Recovers a tree as a nested dict from flat names and values.\n",
    "\n",
    "  This function is useful to analyze checkpoints that are saved by our programs\n",
    "  without need to access the exact source code of the experiment. In particular,\n",
    "  it can be used to extract an reuse various subtrees of the scheckpoint, e.g.\n",
    "  subtree of parameters.\n",
    "  Args:\n",
    "    keys: a list of keys, where '/' is used as separator between nodes.\n",
    "    values: a list of leaf values.\n",
    "  Returns:\n",
    "    A nested tree-like dict.\n",
    "  \"\"\"\n",
    "  tree = {}\n",
    "  sub_trees = collections.defaultdict(list)\n",
    "  for k, v in zip(keys, values):\n",
    "    if '/' not in k:\n",
    "      tree[k] = v\n",
    "    else:\n",
    "      k_left, k_right = k.split('/', 1)\n",
    "      sub_trees[k_left].append((k_right, v))\n",
    "  for k, kv_pairs in sub_trees.items():\n",
    "    k_subtree, v_subtree = zip(*kv_pairs)\n",
    "    tree[k] = recover_tree(k_subtree, v_subtree)\n",
    "  return tree\n",
    "\n",
    "\n",
    "def mod_padding_symmetric(image, factor=64):\n",
    "  \"\"\"Padding the image to be divided by factor.\"\"\"\n",
    "  height, width = image.shape[0], image.shape[1]\n",
    "  height_pad, width_pad = ((height + factor) // factor) * factor, (\n",
    "      (width + factor) // factor) * factor\n",
    "  padh = height_pad - height if height % factor != 0 else 0\n",
    "  padw = width_pad - width if width % factor != 0 else 0\n",
    "  image = jnp.pad(\n",
    "      image, [(padh // 2, padh // 2), (padw // 2, padw // 2), (0, 0)],\n",
    "      mode='reflect')\n",
    "  return image\n",
    "\n",
    "\n",
    "def get_params(ckpt_path):\n",
    "  \"\"\"Get params checkpoint.\"\"\"\n",
    "\n",
    "  with tf.io.gfile.GFile(ckpt_path, 'rb') as f:\n",
    "    data = f.read()\n",
    "  values = np.load(io.BytesIO(data))\n",
    "  params = recover_tree(*zip(*values.items()))\n",
    "  params = params['opt']['target']\n",
    "\n",
    "  return params\n",
    "\n",
    "\n",
    "def calculate_psnr(img1, img2, crop_border, test_y_channel=False):\n",
    "  \"\"\"Calculate PSNR (Peak Signal-to-Noise Ratio).\n",
    "\n",
    "  Ref: https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio\n",
    "  Args:\n",
    "    img1 (ndarray): Images with range [0, 255].\n",
    "    img2 (ndarray): Images with range [0, 255].\n",
    "    crop_border (int): Cropped pixels in each edge of an image. These\n",
    "        pixels are not involved in the PSNR calculation.\n",
    "    test_y_channel (bool): Test on Y channel of YCbCr. Default: False.\n",
    "  Returns:\n",
    "    float: psnr result.\n",
    "  \"\"\"\n",
    "  assert img1.shape == img2.shape, (\n",
    "      f'Image shapes are differnet: {img1.shape}, {img2.shape}.')\n",
    "  img1 = img1.astype(np.float64)\n",
    "  img2 = img2.astype(np.float64)\n",
    "\n",
    "  if crop_border != 0:\n",
    "    img1 = img1[crop_border:-crop_border, crop_border:-crop_border, ...]\n",
    "    img2 = img2[crop_border:-crop_border, crop_border:-crop_border, ...]\n",
    "\n",
    "  if test_y_channel:\n",
    "    img1 = to_y_channel(img1)\n",
    "    img2 = to_y_channel(img2)\n",
    "\n",
    "  mse = np.mean((img1 - img2)**2)\n",
    "  if mse == 0:\n",
    "    return float('inf')\n",
    "  return 20. * np.log10(255. / np.sqrt(mse))\n",
    "\n",
    "\n",
    "def _convert_input_type_range(img):\n",
    "  \"\"\"Convert the type and range of the input image.\n",
    "\n",
    "  It converts the input image to np.float32 type and range of [0, 1].\n",
    "  It is mainly used for pre-processing the input image in colorspace\n",
    "  convertion functions such as rgb2ycbcr and ycbcr2rgb.\n",
    "  Args:\n",
    "    img (ndarray): The input image. It accepts:\n",
    "        1. np.uint8 type with range [0, 255];\n",
    "        2. np.float32 type with range [0, 1].\n",
    "  Returns:\n",
    "      (ndarray): The converted image with type of np.float32 and range of\n",
    "          [0, 1].\n",
    "  \"\"\"\n",
    "  img_type = img.dtype\n",
    "  img = img.astype(np.float32)\n",
    "  if img_type == np.float32:\n",
    "    pass\n",
    "  elif img_type == np.uint8:\n",
    "    img /= 255.\n",
    "  else:\n",
    "    raise TypeError('The img type should be np.float32 or np.uint8, '\n",
    "                    f'but got {img_type}')\n",
    "  return img\n",
    "\n",
    "\n",
    "def _convert_output_type_range(img, dst_type):\n",
    "  \"\"\"Convert the type and range of the image according to dst_type.\n",
    "\n",
    "  It converts the image to desired type and range. If `dst_type` is np.uint8,\n",
    "  images will be converted to np.uint8 type with range [0, 255]. If\n",
    "  `dst_type` is np.float32, it converts the image to np.float32 type with\n",
    "  range [0, 1].\n",
    "  It is mainly used for post-processing images in colorspace convertion\n",
    "  functions such as rgb2ycbcr and ycbcr2rgb.\n",
    "  Args:\n",
    "    img (ndarray): The image to be converted with np.float32 type and\n",
    "        range [0, 255].\n",
    "    dst_type (np.uint8 | np.float32): If dst_type is np.uint8, it\n",
    "        converts the image to np.uint8 type with range [0, 255]. If\n",
    "        dst_type is np.float32, it converts the image to np.float32 type\n",
    "        with range [0, 1].\n",
    "  Returns:\n",
    "    (ndarray): The converted image with desired type and range.\n",
    "  \"\"\"\n",
    "  if dst_type not in (np.uint8, np.float32):\n",
    "    raise TypeError('The dst_type should be np.float32 or np.uint8, '\n",
    "                    f'but got {dst_type}')\n",
    "  if dst_type == np.uint8:\n",
    "    img = img.round()\n",
    "  else:\n",
    "    img /= 255.\n",
    "\n",
    "  return img.astype(dst_type)\n",
    "\n",
    "\n",
    "def rgb2ycbcr(img, y_only=False):\n",
    "  \"\"\"Convert a RGB image to YCbCr image.\n",
    "\n",
    "  This function produces the same results as Matlab's `rgb2ycbcr` function.\n",
    "  It implements the ITU-R BT.601 conversion for standard-definition\n",
    "  television. See more details in\n",
    "  https://en.wikipedia.org/wiki/YCbCr#ITU-R_BT.601_conversion.\n",
    "  It differs from a similar function in cv2.cvtColor: `RGB <-> YCrCb`.\n",
    "  In OpenCV, it implements a JPEG conversion. See more details in\n",
    "  https://en.wikipedia.org/wiki/YCbCr#JPEG_conversion.\n",
    "\n",
    "  Args:\n",
    "    img (ndarray): The input image. It accepts:\n",
    "        1. np.uint8 type with range [0, 255];\n",
    "        2. np.float32 type with range [0, 1].\n",
    "    y_only (bool): Whether to only return Y channel. Default: False.\n",
    "  Returns:\n",
    "    ndarray: The converted YCbCr image. The output image has the same type\n",
    "        and range as input image.\n",
    "  \"\"\"\n",
    "  img_type = img.dtype\n",
    "  img = _convert_input_type_range(img)\n",
    "  if y_only:\n",
    "    out_img = np.dot(img, [65.481, 128.553, 24.966]) + 16.0\n",
    "  else:\n",
    "    out_img = np.matmul(img,\n",
    "                        [[65.481, -37.797, 112.0], [128.553, -74.203, -93.786],\n",
    "                         [24.966, 112.0, -18.214]]) + [16, 128, 128]\n",
    "  out_img = _convert_output_type_range(out_img, img_type)\n",
    "  return out_img\n",
    "\n",
    "\n",
    "def to_y_channel(img):\n",
    "  \"\"\"Change to Y channel of YCbCr.\n",
    "\n",
    "  Args:\n",
    "    img (ndarray): Images with range [0, 255].\n",
    "  Returns:\n",
    "    (ndarray): Images with range [0, 255] (float type) without round.\n",
    "  \"\"\"\n",
    "  img = img.astype(np.float32) / 255.\n",
    "  if img.ndim == 3 and img.shape[2] == 3:\n",
    "    img = rgb2ycbcr(img, y_only=True)\n",
    "    img = img[..., None]\n",
    "  return img * 255.\n",
    "\n",
    "\n",
    "def augment_image(image, times=8):\n",
    "  \"\"\"Geometric augmentation.\"\"\"\n",
    "  if times == 4:  # only rotate image\n",
    "    images = []\n",
    "    for k in range(0, 4):\n",
    "      images.append(np.rot90(image, k=k))\n",
    "    images = np.stack(images, axis=0)\n",
    "  elif times == 8:  # roate and flip image\n",
    "    images = []\n",
    "    for k in range(0, 4):\n",
    "      images.append(np.rot90(image, k=k))\n",
    "    image = np.fliplr(image)\n",
    "    for k in range(0, 4):\n",
    "      images.append(np.rot90(image, k=k))\n",
    "    images = np.stack(images, axis=0)\n",
    "  else:\n",
    "    raise Exception(f'Error times: {times}')\n",
    "  return images\n",
    "\n",
    "\n",
    "def deaugment_image(images, times=8):\n",
    "  \"\"\"Reverse the geometric augmentation.\"\"\"\n",
    "\n",
    "  if times == 4:  # only rotate image\n",
    "    image = []\n",
    "    for k in range(0, 4):\n",
    "      image.append(np.rot90(images[k], k=4-k))\n",
    "    image = np.stack(image, axis=0)\n",
    "    image = np.mean(image, axis=0)\n",
    "  elif times == 8:  # roate and flip image\n",
    "    image = []\n",
    "    for k in range(0, 4):\n",
    "      image.append(np.rot90(images[k], k=4-k))\n",
    "    for k in range(0, 4):\n",
    "      image.append(np.fliplr(np.rot90(images[4+k], k=4-k)))\n",
    "    image = np.mean(image, axis=0)\n",
    "  else:\n",
    "    raise Exception(f'Error times: {times}')\n",
    "  return image\n",
    "\n",
    "\n",
    "def is_image_file(filename):\n",
    "  \"\"\"Check if it is an valid image file by extension.\"\"\"\n",
    "  return any(\n",
    "      filename.endswith(extension)\n",
    "      for extension in ['jpeg', 'JPEG', 'jpg', 'png', 'JPG', 'PNG', 'gif'])\n",
    "\n",
    "\n",
    "def save_img(img, pth):\n",
    "  \"\"\"Save an image to disk.\n",
    "\n",
    "  Args:\n",
    "    img: jnp.ndarry, [height, width, channels], img will be clipped to [0, 1]\n",
    "      before saved to pth.\n",
    "    pth: string, path to save the image to.\n",
    "  \"\"\"\n",
    "  Image.fromarray(np.array(\n",
    "      (np.clip(img, 0., 1.) * 255.).astype(jnp.uint8))).save(pth, 'PNG')\n",
    "\n",
    "\n",
    "def make_shape_even(image):\n",
    "  \"\"\"Pad the image to have even shapes.\"\"\"\n",
    "  height, width = image.shape[0], image.shape[1]\n",
    "  padh = 1 if height % 2 != 0 else 0\n",
    "  padw = 1 if width % 2 != 0 else 0\n",
    "  image = jnp.pad(image, [(0, padh), (0, padw), (0, 0)], mode='reflect')\n",
    "  return image\n",
    "\n",
    "\n",
    "# Refactored code --------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def build_model(task = \"Enhancement\"):\n",
    "  model_mod = importlib.import_module(f'maxim.models.{_MODEL_FILENAME}')\n",
    "  model_configs = ml_collections.ConfigDict(_MODEL_CONFIGS)\n",
    "\n",
    "  model_configs.variant = _MODEL_VARIANT_DICT[task]\n",
    "\n",
    "  model = model_mod.Model(**model_configs)\n",
    "  return model\n",
    "\n",
    "\n",
    "def pre_process(input_file):\n",
    "  '''\n",
    "  Pre-process the image before sending to the model\n",
    "  '''\n",
    "  input_img = np.asarray(Image.open(input_file).convert('RGB'),np.float32) / 255.\n",
    "  # Padding images to have even shapes\n",
    "  height, width = input_img.shape[0], input_img.shape[1]\n",
    "  input_img = make_shape_even(input_img)\n",
    "  height_even, width_even = input_img.shape[0], input_img.shape[1]\n",
    "\n",
    "  # padding images to be multiplies of 64\n",
    "  input_img = mod_padding_symmetric(input_img, factor=64)\n",
    "  input_img = np.expand_dims(input_img, axis=0)\n",
    "\n",
    "  return input_img, height, width, height_even, width_even\n",
    "\n",
    "\n",
    "def predict(input_img):\n",
    "  # handle multi-stage outputs, obtain the last scale output of last stage\n",
    "  return model.apply({'params': flax.core.freeze(params)}, input_img)\n",
    "\n",
    "\n",
    "def post_process(preds, height, width, height_even, width_even):\n",
    "  '''\n",
    "  Post process the image coming out from prediction\n",
    "  '''\n",
    "  if isinstance(preds, list):\n",
    "    preds = preds[-1]\n",
    "    if isinstance(preds, list):\n",
    "      preds = preds[-1]\n",
    "\n",
    "  # De-ensemble by averaging inferenced results.\n",
    "  preds = np.array(preds[0], np.float32)\n",
    "\n",
    "  # unpad images to get the original resolution\n",
    "  new_height, new_width = preds.shape[0], preds.shape[1]\n",
    "  h_start = new_height // 2 - height_even // 2\n",
    "  h_end = h_start + height\n",
    "  w_start = new_width // 2 - width_even // 2\n",
    "  w_end = w_start + width\n",
    "  preds = preds[h_start:h_end, w_start:w_end, :]\n",
    "  return np.array((np.clip(preds, 0., 1.) * 255.).astype(jnp.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63706cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import importlib\n",
    "import ml_collections\n",
    "import tempfile\n",
    "import jax.numpy as jnp\n",
    "import flax\n",
    "from cog import BasePredictor, Path, Input, BaseModel\n",
    "\n",
    "from maxim.run_eval import (\n",
    "    _MODEL_FILENAME,\n",
    "    _MODEL_VARIANT_DICT,\n",
    "    _MODEL_CONFIGS,\n",
    "    get_params,\n",
    "    mod_padding_symmetric,\n",
    "    make_shape_even,\n",
    "    augment_image,\n",
    ")\n",
    "\n",
    "\n",
    "class Predictor(BasePredictor):\n",
    "    def setup(self):\n",
    "\n",
    "        self.params = {\n",
    "            \"Image Denoising\": get_params(\"checkpoints/denoising-SIDD/checkpoint.npz\"),\n",
    "            \"Image Deblurring (GoPro)\": get_params(\n",
    "                \"checkpoints/debluring-GoPro/checkpoint.npz\"\n",
    "            ),\n",
    "            \"Image Deblurring (REDS)\": get_params(\n",
    "                \"checkpoints/debluring-REDS/checkpoint.npz\"\n",
    "            ),\n",
    "            \"Image Deblurring (RealBlur_R)\": get_params(\n",
    "                \"checkpoints/debluring-Real-Blur-R/checkpoint.npz\"\n",
    "            ),\n",
    "            \"Image Deblurring (RealBlur_J)\": get_params(\n",
    "                \"checkpoints/debluring-Real-Blur-J/checkpoint.npz\"\n",
    "            ),\n",
    "            \"Image Deraining (Rain streak)\": get_params(\n",
    "                \"checkpoints/deraining-Rain13k/checkpoint.npz\"\n",
    "            ),\n",
    "            \"Image Deraining (Rain drop)\": get_params(\n",
    "                \"checkpoints/deraining-Raindrop/checkpoint.npz\"\n",
    "            ),\n",
    "            \"Image Dehazing (Indoor)\": get_params(\n",
    "                \"checkpoints/dehazing-RESIDE-Indoor/checkpoint.npz\"\n",
    "            ),\n",
    "            \"Image Dehazing (Outdoor)\": get_params(\n",
    "                \"checkpoints/dehazing-RESIDE-Outdoor/checkpoint.npz\"\n",
    "            ),\n",
    "            \"Image Enhancement (Low-light)\": get_params(\n",
    "                \"checkpoints/enhancement-LOL/checkpoint.npz\"\n",
    "            ),\n",
    "            \"Image Enhancement (Retouching)\": get_params(\n",
    "                \"checkpoints/enhancement-FiveK/checkpoint.npz\"\n",
    "            ),\n",
    "        }\n",
    "\n",
    "        model_mod = importlib.import_module(f\"maxim.models.{_MODEL_FILENAME}\")\n",
    "        self.models = {}\n",
    "        for task in _MODEL_VARIANT_DICT.keys():\n",
    "            model_configs = ml_collections.ConfigDict(_MODEL_CONFIGS)\n",
    "            model_configs.variant = _MODEL_VARIANT_DICT[task]\n",
    "            self.models[task] = model_mod.Model(**model_configs)\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        model: str = Input(\n",
    "            choices=[\n",
    "                \"Image Denoising\",\n",
    "                \"Image Deblurring (GoPro)\",\n",
    "                \"Image Deblurring (REDS)\",\n",
    "                \"Image Deblurring (RealBlur_R)\",\n",
    "                \"Image Deblurring (RealBlur_J)\",\n",
    "                \"Image Deraining (Rain streak)\",\n",
    "                \"Image Deraining (Rain drop)\",\n",
    "                \"Image Dehazing (Indoor)\",\n",
    "                \"Image Dehazing (Outdoor)\",\n",
    "                \"Image Enhancement (Low-light)\",\n",
    "                \"Image Enhancement (Retouching)\",\n",
    "            ],\n",
    "            description=\"Choose a model.\",\n",
    "        ),\n",
    "        image: Path = Input(\n",
    "            description=\"Input image.\",\n",
    "        ),\n",
    "    ) -> Path:\n",
    "\n",
    "        params = self.params[model]\n",
    "        task = model.split()[1]\n",
    "        model = self.models[task]\n",
    "\n",
    "        input_img = (\n",
    "            np.asarray(Image.open(str(image)).convert(\"RGB\"), np.float32) / 255.0\n",
    "        )\n",
    "\n",
    "        # Padding images to have even shapes\n",
    "        height, width = input_img.shape[0], input_img.shape[1]\n",
    "        input_img = make_shape_even(input_img)\n",
    "        height_even, width_even = input_img.shape[0], input_img.shape[1]\n",
    "\n",
    "        # padding images to be multiplies of 64\n",
    "        input_img = mod_padding_symmetric(input_img, factor=64)\n",
    "        input_img = np.expand_dims(input_img, axis=0)\n",
    "\n",
    "        # handle multi-stage outputs, obtain the last scale output of last stage\n",
    "        preds = model.apply({\"params\": flax.core.freeze(params)}, input_img)\n",
    "        if isinstance(preds, list):\n",
    "            preds = preds[-1]\n",
    "            if isinstance(preds, list):\n",
    "                preds = preds[-1]\n",
    "\n",
    "        preds = np.array(preds[0], np.float32)\n",
    "\n",
    "        # unpad images to get the original resolution\n",
    "        new_height, new_width = preds.shape[0], preds.shape[1]\n",
    "        h_start = new_height // 2 - height_even // 2\n",
    "        h_end = h_start + height\n",
    "        w_start = new_width // 2 - width_even // 2\n",
    "        w_end = w_start + width\n",
    "        preds = preds[h_start:h_end, w_start:w_end, :]\n",
    "\n",
    "        # save files\n",
    "        out_path = Path(tempfile.mkdtemp()) / \"output.png\"\n",
    "        Image.fromarray(\n",
    "            np.array((np.clip(preds, 0.0, 1.0) * 255.0).astype(jnp.uint8))\n",
    "        ).save(str(out_path))\n",
    "\n",
    "        return out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3fb3a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time cost: 37.54647970199585s\n"
     ]
    }
   ],
   "source": [
    "from cog import Path\n",
    "from pathlib import Path as PPath\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "# Assuming Predictor class definition is here\n",
    "\n",
    "predictor = Predictor()\n",
    "predictor.setup()\n",
    "end = time.time()\n",
    "print(f'time cost: {end-start}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ca282a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1279458/1539194618.py:2: DeprecationWarning: 'flask.escape' is deprecated and will be removed in Flask 2.4. Import 'markupsafe.escape' instead.\n",
      "  from flask import Flask, escape, request, send_file, jsonify\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from flask import Flask, escape, request, send_file, jsonify\n",
    "from omegaconf import OmegaConf\n",
    "from werkzeug.utils import secure_filename\n",
    "from PIL import Image\n",
    "from cog import Path\n",
    "from pathlib import Path as PPath\n",
    "\"\"\"\n",
    "Remove any leading/trailing whitespace.\n",
    "Remove any invalid characters, such as slashes or non-ASCII characters.\n",
    "Ensure the filename does not start with a period or a tilde, which are typically hidden files on Unix-based systems.\n",
    "If the cleaned filename is empty or only contains a dot, it will be replaced with a random string to prevent empty or hidden filenames.\n",
    "\"\"\"\n",
    "import os\n",
    "flask_app = Flask(__name__)\n",
    "# request.files['image'] 파일 담긴 곳\n",
    "# request.data 그냥 데이터 담긴 곳 => b''\n",
    "# request.form 폼 데이터 담긴 곳 => ImmutableMultiDict([('type', '1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34103102",
   "metadata": {},
   "outputs": [],
   "source": [
    "@flask_app.route('/flask1/maxim/<type>', methods=['POST'])\n",
    "def maxim_response(type):\n",
    "    maxim_models = [    \"Image Denoising\",               # 0\n",
    "                        \"Image Deblurring (GoPro)\",      # 1\n",
    "                        \"Image Deblurring (REDS)\",       # 2\n",
    "                        \"Image Deblurring (RealBlur_R)\", # 3\n",
    "                        \"Image Deblurring (RealBlur_J)\", # 4\n",
    "                        \"Image Deraining (Rain streak)\", # 5\n",
    "                        \"Image Deraining (Rain drop)\",   # 6\n",
    "                        \"Image Dehazing (Indoor)\",       # 7\n",
    "                        \"Image Dehazing (Outdoor)\",      # 8\n",
    "                        \"Image Enhancement (Low-light)\", # 9\n",
    "                        \"Image Enhancement (Retouching)\"]# 10\n",
    "    if request.method == 'POST':\n",
    "        # Check if the request contains an image\n",
    "        if 'image_1' not in request.files:\n",
    "            return \"No image file found in the request\", 400\n",
    "\n",
    "        # Save the uploaded image\n",
    "        image = request.files['image_1']\n",
    "        filename = secure_filename(image.filename)\n",
    "        image_path = os.path.join('uploads', filename)\n",
    "        image.save(image_path)\n",
    "        model_type = int(type)\n",
    "        \n",
    "        output_image_path = predictor.predict(model=maxim_models[model_type], image=Path(image_path))\n",
    "        # Return the saved image as a response\n",
    "        if (image_path.split(\".\")[-1] == \"png\"):\n",
    "            return send_file(PPath(output_image_path), mimetype='image/png')\n",
    "        return send_file(PPath(output_image_path), mimetype='image/jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08c3274",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://70.12.130.121:5000\n",
      "Press CTRL+C to quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dimensions: (246, 284, 3)\n",
      "Padding values: 64\n",
      "sdadasdsadsdsaasdsas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13.124.65.156 - - [19/May/2023 00:33:03] \"POST /flask1/maxim/5 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dimensions: (250, 290, 3)\n",
      "Padding values: 64\n",
      "sdadasdsadsdsaasdsas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13.124.65.156 - - [19/May/2023 00:33:44] \"POST /flask1/maxim/1 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dimensions: (1024, 1024, 3)\n",
      "Padding values: 64\n",
      "sdadasdsadsdsaasdsas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13.124.65.156 - - [19/May/2023 01:18:07] \"POST /flask1/maxim/3 HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    flask_app.run(host=\"0.0.0.0\", port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f773b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#찌꺼기 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca598206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #gpu 사용 확인\n",
    "# from tensorflow.python.client import device_lib\n",
    "# import torch, jax\n",
    "# import tensorflow as tf\n",
    "# print(tf.__version__)\n",
    "# print(tf.config.list_physical_devices('GPU'))\n",
    "# print(device_lib.list_local_devices())\n",
    "# print(torch.cuda.is_available())\n",
    "# print(jax.devices())\n",
    "# # pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# print(\"------------\")\n",
    "# # GPU 할당 변경하기\n",
    "# GPU_NUM = 0 # 원하는 GPU 번호 입력\n",
    "# device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "# torch.cuda.set_device(device) # change allocation of current GPU\n",
    "\n",
    "# print ('# Current cuda device: ', torch.cuda.current_device()) # check\n",
    "# if torch.cuda.is_available():\n",
    "#     torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "#     print(f\"using cuda: {GPU_NUM}, {torch.cuda.get_device_name(GPU_NUM)}\")\n",
    "# x = torch.Tensor([1.0])\n",
    "# print(x.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69caad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# image_path = \"./shake.png\"\n",
    "# model = \"Image Deblurring (RealBlur_R)\"\n",
    "# #                 \"Image Denoising\"\n",
    "# #                 \"Image Deblurring (GoPro)\"\n",
    "# #                 \"Image Deblurring (REDS)\"\n",
    "# #                 \"Image Deblurring (RealBlur_R)\"\n",
    "# #                 \"Image Deblurring (RealBlur_J)\"\n",
    "# #                 \"Image Deraining (Rain streak)\"\n",
    "# #                 \"Image Deraining (Rain drop)\"\n",
    "# #                 \"Image Dehazing (Indoor)\"\n",
    "# #                 \"Image Dehazing (Outdoor)\"\n",
    "# #                 \"Image Enhancement (Low-light)\"\n",
    "# #                 \"Image Enhancement (Retouching)\"\n",
    "# output_image_path = predictor.predict(model=model, image=Path(image_path))\n",
    "\n",
    "# # Load the enhanced image using PIL and display or save it\n",
    "# from PIL import Image\n",
    "\n",
    "# enhanced_image = Image.open(PPath(output_image_path))\n",
    "# enhanced_image.show()\n",
    "# enhanced_image.save(\"enhanced_test_scs.png\")\n",
    "# end = time.time()\n",
    "# print(f'time cost: {end-start}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d361ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight_drive_path = 'https://drive.google.com/uc?id=1-BRKozXh81PtwoMZ9QN3kCAieLzozHIq' # Path of the weights file which in the Google Drive\n",
    "# MODEL_PATH = './adobe.npz' # name of the model to be saved as\n",
    "\n",
    "# gdown.download(weight_drive_path, MODEL_PATH, quiet=False) # Download Model weights to your current instance\n",
    "\n",
    "\n",
    "# FLAGS = DummyFlags(ckpt_path = MODEL_PATH, task = \"Deblurring\") # Path to your checkpoint and task name\n",
    "# #     'Denoising': 'S-3',\n",
    "# #     'Deblurring': 'S-3',\n",
    "# #     'Deraining': 'S-2',\n",
    "# #     'Dehazing': 'S-2',\n",
    "# #     'Enhancement': 'S-2',\n",
    "# params = get_params(FLAGS.ckpt_path) # Parse the config\n",
    "\n",
    "# model = build_model() # Build Model\n",
    "\n",
    "# import time\n",
    "# start = time.time()\n",
    "# image_path = \"./123.png\" # your image path\n",
    "# input_img, height, width, height_even, width_even = pre_process(image_path)\n",
    "# enhanced_image_array = predict(input_img) # Get predictions\n",
    "# enhanced_image_array = post_process(enhanced_image_array, height, width, height_even, width_even)\n",
    "# end = time.time()\n",
    "# print(f'time cost: {end-start}')\n",
    "\n",
    "# enhanced_pil_image = Image.fromarray(enhanced_image_array) # get PIL image from array\n",
    "# enhanced_pil_image.save(\"./result/resultImage.png\") # Save the image\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as img\n",
    "# #강화 전\n",
    "# img_test = img.imread('./shake.png')\n",
    "# plt.imshow(img_test)\n",
    "# plt.show()\n",
    "# #강화 후\n",
    "# img_test = img.imread('./result/resultImage.png')\n",
    "# plt.imshow(img_test)\n",
    "# plt.show()\n",
    "# # 압축 models 압축 푸는 코드\n",
    "# # os.system(\"unzip checkpoints.zip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
